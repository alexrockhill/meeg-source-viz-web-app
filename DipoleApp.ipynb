{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEG/EEG Dipole Interactive Example\n",
    "\n",
    "This notebook is an interactive example of how dipoles manifest at the scalp through electromagnetic conduction and detection via electrodes (EEG) and gradiometers and magnetometers (MEG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ab432a60bb43fb8fc2b1cbb1e9baed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(FileUpload(value={}, accept='*.fif', description='Upload'), Text(value=''))),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /tmp/temp-ave.fif ...\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -199.80 ...     499.49 ms (Left Auditory)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 55 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -199.80 ...     499.49 ms (Right Auditory)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 61 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -199.80 ...     499.49 ms (Left visual)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 67 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102) active\n",
      "        PCA-v2 (1 x 102) active\n",
      "        PCA-v3 (1 x 102) active\n",
      "        Average EEG reference (1 x 60) active\n",
      "    Found the data of interest:\n",
      "        t =    -199.80 ...     499.49 ms (Right visual)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 58 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    }
   ],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "\n",
    "import mne\n",
    "from mne.datasets import sample\n",
    "\n",
    "from mayavi import mlab\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "data_path = sample.data_path()\n",
    "subjects_dir = subjects_dir = op.join(data_path, 'subjects')\n",
    "data_dir = op.join(data_path, 'MEG', 'sample')\n",
    "\n",
    "# setup sorce space\n",
    "src = mne.setup_source_space('sample', subjects_dir=subjects_dir,\n",
    "                             spacing='oct6')\n",
    "\n",
    "# get info for forward model\n",
    "fname_trans = op.join(data_dir, 'sample_audvis_raw-trans.fif')\n",
    "fname_bem_eeg = op.join(subjects_dir, 'sample', 'bem',\n",
    "                        'sample-5120-5120-5120-bem-sol.fif')\n",
    "fname_bem_meg = op.join(subjects_dir, 'sample', 'bem',\n",
    "                        'sample-5120-bem-sol.fif')\n",
    "\n",
    "# read in evoked\n",
    "fname = op.join(data_dir, 'sample_audvis-ave.fif')\n",
    "evoked = mne.read_evokeds(fname, baseline=(None, 0), proj=True)[0]\n",
    "info = evoked.info\n",
    "\n",
    "fwd_eeg = mne.make_forward_solution(info, trans=fname_trans,\n",
    "                                    src=src, bem=fname_bem_eeg,\n",
    "                                    eeg=True, meg=False)\n",
    "\n",
    "fwd_meg = mne.make_forward_solution(info, trans=fname_trans,\n",
    "                                    src=src, bem=fname_bem_meg,\n",
    "                                    meg=True, eeg=False)\n",
    "\n",
    "# setup data\n",
    "fname_stc_eeg = op.join(data_dir, 'sample_audvis-eeg-lh.stc')\n",
    "stc_eeg = mne.read_source_estimate(fname_stc_eeg)\n",
    "stc_eeg = stc_eeg.crop(tmax=stc.times[0])  # we just need one time point\n",
    "\n",
    "fname_stc_meg = op.join(data_dir, 'sample_audvis-meg-lh.stc')\n",
    "stc_meg = mne.read_source_estimate(fname_stc_meg)\n",
    "stc_meg = stc_meg.crop(tmax=stc.times[0])  # we just need one time point\n",
    "\n",
    "# components for GUI\n",
    "strength = widgets.IntSlider(min=0, max=100, step=1, value=10)\n",
    "r = widgets.FloatSlider(min=0., max=1., step=0.1, value=0.1)\n",
    "phi = widgets.IntSlider(min=0, max=360, step=1)\n",
    "theta = widgets.IntSlider(min=0, max=180, step=1)\n",
    "x = widgets.FloatSlider(min=-1.0, max=1.0, step=0.01, value=0.)\n",
    "y = widgets.FloatSlider(min=-1.0, max=1.0, step=0.01, value=0.)\n",
    "z = widgets.FloatSlider(min=-1.0, max=1.0, step=0.01, value=0.)\n",
    "modality = widgets.RadioButtons(\n",
    "    options=['grad', 'mag', 'eeg'],\n",
    "    description='Modality: ',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "plot = mlab.quiver3d(x.value, y.value, z.value,\n",
    "                     *get_uvw(r.value, phi.value,\n",
    "                              theta.value),\n",
    "                     line_width=strength.value,\n",
    "                     scale_factor=1e-2)\n",
    "\n",
    "def get_uvw(r, theta, phi):\n",
    "    u = r * np.cos(theta) * np.sin(phi)\n",
    "    v = r * np.sin(theta) * np.sin(phi)\n",
    "    w = r * np.cos(phi)\n",
    "    return u, v, w\n",
    "\n",
    "def set_stc_data(stc, x, y, z, u, v, w, strength):\n",
    "    stc.data[:] = 0\n",
    "    \n",
    "    return stc\n",
    "\n",
    "ui = widgets.HBox([strength, r, phi, theta, x, y, z, modality])\n",
    "def update_dipole(strength, r, phi, theta, x, y, z, modality):\n",
    "    u, v, w = get_uvw(r, phi, theta)\n",
    "    # TO DO: get source space locations, create vector,\n",
    "    # assign source space activity based on vector,\n",
    "    # plot source space\n",
    "    if modality == 'eeg':\n",
    "        stc_eeg = set_stc_data(stc_eeg, x, y, z, u, v, w, strength)\n",
    "        evoked = mne.forward.apply_forward(fwd_eeg, stc_eeg,\n",
    "                                           info, on_missing='ignore')\n",
    "    else:\n",
    "        stc_meg = set_stc_data(stc_meg, x, y, z, u, v, w, strength)\n",
    "        evoked = mne.forward.apply_forward(fwd_meg, stc_meg,\n",
    "                                           info, on_missing='ignore')\n",
    "    maps = mne.make_field_map(evoked, trans=fname_trans, subject='sample',\n",
    "                              subjects_dir=subjects_dir, n_jobs=1)\n",
    "    field_map = evoked.plot_field(maps)\n",
    "    plot.mlab_source.trait_set(x=x, y=y, z=z, u=u, v=v, w=w,\n",
    "                               line_width=strenght)\n",
    "    \n",
    "\n",
    "out = widgets.interactive_output(update_dipole,\n",
    "                                 {'strength': strength,\n",
    "                                  'r': r, 'phi': phi, 'theta': theta,\n",
    "                                  'x': x, 'y': y, 'z':, z,\n",
    "                                  'modality': modality})\n",
    "\n",
    "display(ui, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
